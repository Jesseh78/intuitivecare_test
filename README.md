# IntuitiveCare - Pipeline ETL e API de An√°lise de Despesas

##  Vis√£o Geral

Este projeto implementa uma solu√ß√£o completa de **ETL (Extract, Transform, Load)** para an√°lise de despesas de operadoras de planos de sa√∫de brasileiras, utilizando dados p√∫blicos da **ANS (Ag√™ncia Nacional de Sa√∫de Suplementar)**.

### O que o projeto faz:

1. **Pipeline ETL automatizado**:
   - Baixa automaticamente os √∫ltimos 3 trimestres de demonstra√ß√µes cont√°beis da ANS
   - Valida e enriquece dados com cadastro de operadoras ativas
   - Agrega informa√ß√µes por operadora e UF
   - Exporta dados processados para PostgreSQL

2. **Banco de dados PostgreSQL**:
   - Schema normalizado com constraints e √≠ndices
   - Views materializadas para consultas otimizadas
   - Queries anal√≠ticas pr√©-constru√≠das (top 5, crescimento, etc.)

3. **API REST (FastAPI)**:
   - Listagem de operadoras com pagina√ß√£o e busca
   - Hist√≥rico de despesas por operadora
   - Estat√≠sticas agregadas com cache em mem√≥ria
   - Documenta√ß√£o interativa (Swagger)

---

##  Requisitos

### Obrigat√≥rios:
- **Python 3.10+**
- **Docker Desktop** (para PostgreSQL)
- **Git**

### Bibliotecas Python (instaladas via requirements.txt):
- `pandas` (processamento de dados)
- `requests` (download de arquivos ANS)
- `fastapi` + `uvicorn` (API REST)
- `psycopg[binary]` (PostgreSQL driver)
- `openpyxl` (leitura de Excel)

---

##  Setup R√°pido

Voc√™ pode executar o projeto de **duas formas**:
- **Op√ß√£o A**: Com Docker (recomendado) - tudo containerizado
- **Op√ß√£o B**: Desenvolvimento local - API local + DB Docker

---

### Op√ß√£o A: Setup com Docker (Recomendado)

#### 1. Clone o reposit√≥rio
```bash
git clone <url-do-repo>
cd intuitivecare_test
```

#### 2. Configure as vari√°veis de ambiente
```bash
# Copie o template e edite se necess√°rio
cp .env.example .env

# Ou no Windows
copy .env.example .env
```

#### 3. Inicie todos os servi√ßos (API + DB)
```bash
docker-compose up -d
```

**O que isso faz:**
- ‚úÖ Cria o banco PostgreSQL na porta **5434**
- ‚úÖ Builda a imagem da API
- ‚úÖ Inicia a API na porta **8000**
- ‚úÖ Configura rede e health checks

#### 4. Verifique se os containers est√£o rodando
```bash
docker ps
```

Voc√™ deve ver:
```
CONTAINER ID   IMAGE                    STATUS         PORTS
abc123         intuitivecare_test-api   Up 30 seconds  0.0.0.0:8000->8000/tcp
def456         postgres:16              Up 30 seconds  0.0.0.0:5434->5432/tcp
```

#### 5. Acesse a API
- **Swagger UI**: http://localhost:8000/docs
- **Health check**: http://localhost:8000/api/operadoras?limit=1

#### 6. Para parar os servi√ßos
```bash
# Parar sem remover containers
docker-compose stop

# Parar e remover containers
docker-compose down

# Parar e remover TUDO (incluindo volumes/dados)
docker-compose down -v
```

---

### Op√ß√£o B: Setup Local (Desenvolvimento)

#### 1. Clone o reposit√≥rio
```bash
git clone <url-do-repo>
cd intuitivecare_test
```

#### 2. Crie e ative o ambiente virtual
```bash
# Windows PowerShell
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Windows CMD
python -m venv .venv
.venv\Scripts\activate.bat

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

#### 3. Instale as depend√™ncias
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 4. Inicie apenas o banco de dados
```bash
docker-compose up -d db
```

#### 5. Configure a vari√°vel de ambiente para localhost
```bash
# Windows PowerShell
$env:DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"

# Windows CMD
set DATABASE_URL=postgresql://intuitive:intuitive@localhost:5434/intuitivecare

# Linux/Mac
export DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"
```

**Nota**: Use porta **5434** (externa) quando a API roda localmente!

---

## üêò Configura√ß√£o do PostgreSQL

### Testar conex√£o com o banco
```bash
# Windows PowerShell
docker exec -it intuitivecare_pg psql -U intuitive -d intuitivecare -c "SELECT version();"
```

**Configura√ß√µes do banco**:
- **Host**: `localhost` (API local) ou `db` (API Docker)
- **Porta**: `5434` (API local) ou `5432` (API Docker)
- **Usu√°rio**: `intuitive`
- **Senha**: `intuitive`
- **Database**: `intuitivecare`

---

##  Executar o Pipeline ETL

O pipeline √© dividido em 3 etapas sequenciais:

### Step 1: Baixar e consolidar dados da ANS
```bash
python -m src.cli step1
```

**O que faz**:
- Acessa o FTP p√∫blico da ANS
- Identifica os √∫ltimos 3 trimestres dispon√≠veis
- Baixa ZIPs das demonstra√ß√µes cont√°beis
- Extrai e normaliza tabelas (CSV/Excel)
- Gera: `data/processed/consolidado_despesas.csv`

**Colunas geradas**: `CNPJ, RazaoSocial, Ano, Trimestre, ValorDespesas`

---

### Step 2: Validar, enriquecer e agregar
```bash
python -m src.cli step2 --invalid-cnpj-strategy keep_mark
```

**O que faz**:
- Valida CNPJs (d√≠gitos verificadores)
- Baixa cadastro de operadoras ativas da ANS
- Enriquece com: `RegistroANS, Modalidade, UF`
- Gera agrega√ß√µes por operadora/UF (total, m√©dia, desvio padr√£o)

**Arquivos gerados**:
- `data/processed/consolidado_enriquecido.csv`
- `data/processed/operadoras_ativas_normalizado.csv`
- `data/processed/despesas_agregadas.csv`
- `data/processed/invalid_rows_step2.csv` (CNPJs inv√°lidos, se `keep_mark`)
- `data/processed/join_sem_match_step2.csv` (CNPJs sem match no cadastro)

**Op√ß√µes de estrat√©gia**:
- `--invalid-cnpj-strategy drop`: Remove linhas com CNPJ inv√°lido
- `--invalid-cnpj-strategy keep_mark` (**recomendado**): Mant√©m marcado para auditoria

---

### Step 3: Exportar para SQL
```bash
python -m src.cli export-sql
```

**O que faz**:
- Converte colunas para snake_case (padr√£o SQL)
- Gera CSVs prontos para `\copy` do PostgreSQL
- Salva em: `data/sql_data/`

**Arquivos gerados**:
- `operadoras_ativas.csv`
- `consolidado_enriquecido.csv`
- `despesas_agregadas.csv`
- `consolidado_despesas.csv` (c√≥pia do step1)

---

##  Aplicar Schema e Views no PostgreSQL

### 1. Criar tabelas e √≠ndices
```bash
# Windows PowerShell
type sql\01_schema.sql | docker exec -i intuitivecare_pg psql -U intuitive -d intuitivecare

# Linux/Mac
cat sql/01_schema.sql | docker exec -i intuitivecare_pg psql -U intuitive -d intuitivecare
```

**Tabelas criadas**:
- `operadoras_ativas` (PK: cnpj)
- `despesas_trimestrais` (FK ‚Üí operadoras_ativas)
- `despesas_agregadas` (estat√≠sticas pr√©-calculadas)

---

### 2. Criar views
```bash
# Windows PowerShell
type sql\04_views.sql | docker exec -i intuitivecare_pg psql -U intuitive -d intuitivecare
```

**Views criadas**:
- `operadoras_ativas_view` (une cadastro + raz√£o social das despesas)

---

##  Carga de Dados no PostgreSQL

### 1. Copie os CSVs para dentro do container
```bash
docker cp data/sql_data/. intuitivecare_pg:/tmp/sql_data/
```

### 2. Execute a carga via psql
```bash
# Windows PowerShell
docker exec -it intuitivecare_pg psql -U intuitive -d intuitivecare
```

Dentro do psql:
```sql
-- Limpa dados anteriores (se re-executar)
TRUNCATE TABLE despesas_trimestrais CASCADE;
TRUNCATE TABLE despesas_agregadas RESTART IDENTITY;
TRUNCATE TABLE operadoras_ativas CASCADE;

-- Carga: operadoras ativas
\copy operadoras_ativas (cnpj, registro_ans, modalidade, uf) FROM '/tmp/sql_data/operadoras_ativas.csv' WITH (FORMAT csv, HEADER true, ENCODING 'UTF8');

-- Carga: despesas trimestrais enriquecidas
\copy despesas_trimestrais (cnpj, razao_social, trimestre, ano, valor_despesas, registro_ans, modalidade, uf) FROM '/tmp/sql_data/consolidado_enriquecido.csv' WITH (FORMAT csv, HEADER true, ENCODING 'UTF8');

-- Carga: agregados
\copy despesas_agregadas (razao_social, uf, total_despesas, media_despesas_tri, desvio_padrao_despesas) FROM '/tmp/sql_data/despesas_agregadas.csv' WITH (FORMAT csv, HEADER true, ENCODING 'UTF8');

-- Verifica
SELECT COUNT(*) FROM operadoras_ativas;
SELECT COUNT(*) FROM despesas_trimestrais;
SELECT COUNT(*) FROM despesas_agregadas;

\q
```

**Importante**: Use `CASCADE` no TRUNCATE para respeitar a FK entre tabelas.

---

##  Rodar a API REST

### Op√ß√£o A: API via Docker (j√° est√° rodando!)

Se voc√™ usou `docker-compose up -d`, a API j√° est√° dispon√≠vel em:
- **Base URL**: http://localhost:8000
- **Swagger**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

**Logs da API**:
```bash
# Ver logs em tempo real
docker logs -f intuitivecare_api

# Ver √∫ltimas 100 linhas
docker logs --tail 100 intuitivecare_api
```

**Rebuild da imagem** (ap√≥s mudan√ßas no c√≥digo):
```bash
docker-compose up -d --build api
```

---

### Op√ß√£o B: API local (desenvolvimento)

#### 1. Configure a vari√°vel de ambiente
```bash
# Windows PowerShell
$env:DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"

# Windows CMD
set DATABASE_URL=postgresql://intuitive:intuitive@localhost:5434/intuitivecare

# Linux/Mac
export DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"
```

**Ou crie arquivo `.env`**:
```bash
cp .env.example .env
```

Edite `.env` e ajuste `DATABASE_URL`:
```
DATABASE_URL=postgresql://intuitive:intuitive@localhost:5434/intuitivecare
```

#### 2. Inicie o servidor
```bash
uvicorn src.api.main:app --reload --port 8000
```

#### 3. Acesse a documenta√ß√£o interativa
- Swagger UI: **http://localhost:8000/docs**
- ReDoc: **http://localhost:8000/redoc**

---

##  Endpoints da API

### 1. **GET** `/api/operadoras` - Listar operadoras
**Pagina√ß√£o + filtro por raz√£o social ou CNPJ**

```bash
# Listar primeira p√°gina (10 itens)
curl "http://localhost:8000/api/operadoras?page=1&limit=10"

# Buscar por raz√£o social
curl "http://localhost:8000/api/operadoras?q=UNIMED"

# Buscar por CNPJ
curl "http://localhost:8000/api/operadoras?q=12345678"
```

**Resposta**:
```json
{
  "data": [
    {
      "cnpj": "12345678000199",
      "razao_social": "UNIMED EXAMPLE COOPERATIVA",
      "registro_ans": "123456",
      "modalidade": "Cooperativa M√©dica",
      "uf": "SP"
    }
  ],
  "total": 150,
  "page": 1,
  "limit": 10
}
```

---

### 2. **GET** `/api/operadoras/{cnpj}` - Detalhes de uma operadora
```bash
curl "http://localhost:8000/api/operadoras/12345678000199"
```

**Resposta**:
```json
{
  "cnpj": "12345678000199",
  "razao_social": "UNIMED EXAMPLE COOPERATIVA",
  "registro_ans": "123456",
  "modalidade": "Cooperativa M√©dica",
  "uf": "SP"
}
```

---

### 3. **GET** `/api/operadoras/{cnpj}/despesas` - Hist√≥rico de despesas
```bash
curl "http://localhost:8000/api/operadoras/12345678000199/despesas"
```

**Resposta**:
```json
[
  {
    "ano": 2025,
    "trimestre": 1,
    "valor_despesas": 1500000.00
  },
  {
    "ano": 2025,
    "trimestre": 2,
    "valor_despesas": 1750000.00
  }
]
```

---

### 4. **GET** `/api/estatisticas` - Estat√≠sticas agregadas
**Cache em mem√≥ria (TTL: 5 minutos)**

```bash
# Normal (usa cache se dispon√≠vel)
curl "http://localhost:8000/api/estatisticas"

# For√ßar rec√°lculo (ignora cache)
curl "http://localhost:8000/api/estatisticas?force=true"
```

**Resposta**:
```json
{
  "total_despesas": 15000000000.00,
  "media_despesas": 2500000.00,
  "top5_operadoras": [
    {
      "razao_social": "BRADESCO SAUDE S/A",
      "total_despesas": 500000000.00
    }
  ],
  "distribuicao_por_uf": [
    {
      "uf": "SP",
      "total_despesas": 8000000000.00
    }
  ],
  "cached": true
}
```

---

## üß™ Testes

O projeto inclui **testes unit√°rios e de integra√ß√£o** usando pytest.

### Executar todos os testes

```bash
# Instale depend√™ncias de desenvolvimento
pip install -r requirements-dev.txt

# Execute todos os testes
pytest

# Com coverage report
pytest --cov=src --cov-report=html

# Apenas testes unit√°rios
pytest tests/test_cnpj.py tests/test_parse_valor.py tests/test_aggregate.py

# Apenas testes de integra√ß√£o (API)
pytest tests/test_api.py
```

### Cobertura de testes

Os testes cobrem:

**Unit√°rios** (11 testes):
- ‚úÖ Valida√ß√£o de CNPJ (v√°lidos, inv√°lidos, formatados)
- ‚úÖ Normaliza√ß√£o de CNPJ (remo√ß√£o de pontos, barras, etc.)
- ‚úÖ Parse de valores monet√°rios (formato BR e internacional)
- ‚úÖ Agrega√ß√µes (total, m√©dia, desvio padr√£o)

**Integra√ß√£o** (9 testes):
- ‚úÖ GET `/api/operadoras` - retorna 200 com pagina√ß√£o
- ‚úÖ GET `/api/operadoras?q=` - filtro de busca
- ‚úÖ GET `/api/operadoras/{cnpj}` - detalhes operadora
- ‚úÖ GET `/api/operadoras/{cnpj}` - retorna 404 se n√£o existir
- ‚úÖ GET `/api/operadoras/{cnpj}/despesas` - hist√≥rico
- ‚úÖ GET `/api/estatisticas` - campos obrigat√≥rios
- ‚úÖ GET `/api/estatisticas?force=true` - for√ßa refresh
- ‚úÖ GET `/docs` - Swagger dispon√≠vel
- ‚úÖ GET `/redoc` - ReDoc dispon√≠vel

### Estrutura de testes

```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ test_cnpj.py          # Valida√ß√£o e normaliza√ß√£o de CNPJ (11 testes)
‚îú‚îÄ‚îÄ test_parse_valor.py   # Parse de valores monet√°rios (10 testes)
‚îú‚îÄ‚îÄ test_aggregate.py     # Agrega√ß√µes estat√≠sticas (8 testes)
‚îî‚îÄ‚îÄ test_api.py           # Testes de integra√ß√£o da API (9 testes)
```

### Visualizar relat√≥rio de coverage

Ap√≥s executar `pytest --cov`, abra:
```
htmlcov/index.html
```

---

##  Estrutura do Projeto

```
intuitivecare_test/
‚îÇ
‚îú‚îÄ‚îÄ data/                                    # Dados processados
‚îÇ   ‚îú‚îÄ‚îÄ raw/                                 # CSVs baixados da ANS (por trimestre)
‚îÇ   ‚îú‚îÄ‚îÄ processed/                           # Sa√≠da do pipeline (consolidado, enriquecido, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ reference/                           # Cadastros baixados da ANS
‚îÇ   ‚îî‚îÄ‚îÄ sql_data/                            # CSVs prontos para carga no PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ sql/                                     # Scripts SQL
‚îÇ   ‚îú‚îÄ‚îÄ 01_schema.sql                        # CREATE TABLE + √≠ndices
‚îÇ   ‚îú‚îÄ‚îÄ 02_load.sql                          # Exemplo de \copy (refer√™ncia)
‚îÇ   ‚îú‚îÄ‚îÄ 03_queries.sql                       # Queries anal√≠ticas (top 5, crescimento, UFs)
‚îÇ   ‚îî‚îÄ‚îÄ 04_views.sql                         # CREATE VIEW (operadoras_ativas_view)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                                 # API REST (FastAPI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                          # Rotas e endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                       # Pydantic models (request/response)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.py                       # L√≥gica de neg√≥cio (queries SQL)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db.py                            # Conex√£o com PostgreSQL (psycopg)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                            # Pipeline ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ans_fetch.py                     # Step 1: baixa e consolida dados ANS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validate_enrich.py               # Step 2: valida CNPJ, enriquece com cadastro
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aggregate.py                     # Step 2: agrega por operadora/UF
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export_sql_data.py               # Step 3: prepara CSVs para PostgreSQL
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                               # Utilit√°rios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fs.py                            # Helpers para sistema de arquivos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ http.py                          # Download de arquivos (requests)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ cli.py                               # Interface de linha de comando (argparse)
‚îÇ
‚îú‚îÄ‚îÄ tests/                                   # Testes automatizados (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ test_cnpj.py                         # Valida√ß√£o e normaliza√ß√£o de CNPJ
‚îÇ   ‚îú‚îÄ‚îÄ test_parse_valor.py                 # Parse de valores monet√°rios
‚îÇ   ‚îú‚îÄ‚îÄ test_aggregate.py                   # Agrega√ß√µes estat√≠sticas
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py                         # Testes de integra√ß√£o da API
‚îÇ
‚îú‚îÄ‚îÄ .dockerignore                            # Arquivos exclu√≠dos do build Docker
‚îú‚îÄ‚îÄ .env.example                             # Template de vari√°veis de ambiente
‚îú‚îÄ‚îÄ docker-compose.yml                       # Orquestra√ß√£o (API + PostgreSQL)
‚îú‚îÄ‚îÄ Dockerfile                               # Imagem Docker da API
‚îú‚îÄ‚îÄ pytest.ini                               # Configura√ß√£o do pytest
‚îú‚îÄ‚îÄ requirements.txt                         # Depend√™ncias de produ√ß√£o
‚îú‚îÄ‚îÄ requirements-dev.txt                     # Depend√™ncias de desenvolvimento
‚îî‚îÄ‚îÄ README.md                                # Este arquivo
```

---

##  Decis√µes T√©cnicas e Tradeoffs

### 1. **Estrat√©gia `keep_mark` para CNPJs inv√°lidos**
**Por qu√™?**  
- Mant√©m rastreabilidade para auditoria
- Permite identificar problemas nos dados da ANS
- N√£o perde informa√ß√£o (pode ser corrigida manualmente)

**Tradeoff**:  
- ‚ùå Gera linhas √≥rf√£s (sem FK v√°lida)
- ‚úÖ Mant√©m integridade anal√≠tica (saber o que foi descartado)

**Alternativa**: `drop` (remove silenciosamente, pode esconder problemas)

---

### 2. **Encoding `latin-1` para cadastro ANS**
**Por qu√™?**  
- Arquivos da ANS usam `Windows-1252` (n√£o UTF-8)
- Evita `UnicodeDecodeError` ao ler CSVs com acentua√ß√£o

**Tradeoff**:  
- ‚ùå N√£o √© port√°vel (depende do encoding do servidor ANS)
- ‚úÖ Funciona com dados reais (testado)

**Alternativa**: Converter manualmente para UTF-8 (adiciona etapa extra)

---

### 3. **Cache em mem√≥ria (5 minutos) para estat√≠sticas**
**Por qu√™?**  
- Reduz carga no banco para queries pesadas (SUM, AVG, GROUP BY)
- API responde mais r√°pido (< 10ms vs 500ms)

**Tradeoff**:  
- ‚ùå Dados podem estar desatualizados por at√© 5 minutos
- ‚úÖ Escalabilidade (suporta mais requests simult√¢neos)

**Alternativa**: Cache em Redis (mais complexo, mas distribu√≠do)

---

### 4. **Porta 5434 (n√£o 5432) para PostgreSQL**
**Por qu√™?**  
- Evita conflito com PostgreSQL local (porta padr√£o 5432)
- Facilita desenvolvimento (m√∫ltiplos projetos)

**Tradeoff**:  
- ‚ùå Precisa lembrar de configurar porta customizada
- ‚úÖ Isolamento total (n√£o interfere com outros bancos)

---

### 5. **Download autom√°tico vs. manual da ANS**
**Por qu√™?**  
- Automatiza coleta (reduz erro humano)
- Identifica √∫ltimo trimestre dispon√≠vel dinamicamente

**Tradeoff**:  
- ‚ùå Depende de disponibilidade do FTP ANS (pode cair)
- ‚úÖ Atualiza√ß√£o autom√°tica (executar step1 novamente sempre busca √∫ltimos dados)

**Alternativa**: Fornecer CSVs manualmente (mais controle, menos automa√ß√£o)

---

### 6. **FK com DEFERRABLE INITIALLY DEFERRED**
**Por qu√™?**  
- Permite carga em qualquer ordem (operadoras ‚Üí despesas ou vice-versa)
- Evita erro de viola√ß√£o de FK durante `\copy`

**Tradeoff**:  
- ‚ùå Valida√ß√£o acontece s√≥ no COMMIT (erros aparecem mais tarde)
- ‚úÖ Flexibilidade na carga (n√£o precisa respeitar ordem estrita)

---

### 7. **Pandas para ETL (n√£o Spark/Dask)**
**Por qu√™?**  
- Volume de dados pequeno (~50-100MB por trimestre)
- Simplicidade (sem cluster, menos depend√™ncias)

**Tradeoff**:  
- ‚ùå N√£o escala para Big Data (limite: ~1-2GB de RAM)
- ‚úÖ Setup r√°pido, f√°cil debug

**Alternativa**: Spark/Dask (overkill para esse volume)

---

### 8. **FastAPI (n√£o Flask/Django)**
**Por qu√™?**  
- Performance (ass√≠ncrono por padr√£o)
- Valida√ß√£o autom√°tica (Pydantic)
- Documenta√ß√£o Swagger embutida

**Tradeoff**:  
- ‚ùå Menos maturidade que Flask (menos plugins)
- ‚úÖ C√≥digo mais limpo (type hints nativos)

---

## üîß Troubleshooting

### Problema 1: **Container da API n√£o inicia**
```
Error: Cannot connect to database
```

**Solu√ß√£o**: Certifique-se que o DB est√° rodando e healthy:
```bash
docker ps

# Se o DB n√£o estiver UP, reinicie
docker-compose restart db

# Aguarde o health check
docker logs intuitivecare_pg | grep "ready to accept connections"

# Reinicie a API
docker-compose restart api
```

---

### Problema 2: **Porta 8000 j√° est√° em uso**
```
Error: address already in use
```

**Solu√ß√£o**: Mude a porta no `.env`:
```
API_PORT=8001
```

Ou pare o processo que est√° usando:
```bash
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

---

### Problema 3: **SSL Error ao baixar da ANS**
```
SSLError: [SSL: CERTIFICATE_VERIFY_FAILED]
```

**Solu√ß√£o**:
```python
# Adicione verify=False no requests (src/utils/http.py)
# Apenas para desenvolvimento local!
response = requests.get(url, verify=False)
```

---

### Problema 4: **Encoding error ao ler cadastro**
```
UnicodeDecodeError: 'utf-8' codec can't decode byte
```

**Solu√ß√£o**: Cadastro ANS usa `latin-1`, j√° configurado em `validate_enrich.py`:
```python
cad = pd.read_csv(path, encoding="latin-1", sep=";")
```

---

### Problema 3: **FK constraint error na carga**
```
ERROR: insert or update on table "despesas_trimestrais" violates foreign key
```

**Solu√ß√£o**: Limpe na ordem correta:
```sql
TRUNCATE TABLE despesas_trimestrais CASCADE;
TRUNCATE TABLE operadoras_ativas CASCADE;
```

Ou use `DEFERRABLE` (j√° configurado no schema).

---

### Problema 7: **Windows n√£o reconhece vari√°vel de ambiente**
```bash
# PowerShell
$env:DATABASE_URL="postgresql://..."

# CMD
set DATABASE_URL=postgresql://...
```

**Alternativa**: Crie arquivo `.env`:
```bash
cp .env.example .env
```

E a API ler√° automaticamente (com `python-dotenv`).

---

### Problema 8: **Container PostgreSQL n√£o inicia**
```
Error: port 5434 already in use
```

**Solu√ß√£o**:
```bash
# Verifique processo usando a porta
netstat -ano | findstr :5434

# Ou mude a porta no docker-compose.yml
ports:
  - "5435:5432"  # Porta externa diferente
```

---

### Problema 6: **Dados n√£o aparecem na API**
**Checklist**:
1. Pipeline executado? (`step1` ‚Üí `step2` ‚Üí `export-sql`)
2. Schema criado? (`01_schema.sql`)
3. Carga feita? (`\copy` dos CSVs)
4. Views criadas? (`04_views.sql`)
5. `DATABASE_URL` correto?

**Debug**:
```bash
docker exec -it intuitivecare_pg psql -U intuitive -d intuitivecare -c "SELECT COUNT(*) FROM despesas_trimestrais;"
```

---

##  Refer√™ncias

- **Dados p√∫blicos ANS**: https://dadosabertos.ans.gov.br/
- **FastAPI Docs**: https://fastapi.tiangolo.com/
- **PostgreSQL COPY**: https://www.postgresql.org/docs/current/sql-copy.html
- **Pandas Docs**: https://pandas.pydata.org/docs/
- **Docker Docs**: https://docs.docker.com/

---

##  Arquivos de Configura√ß√£o

### `.env.example`
Template com todas as vari√°veis de ambiente necess√°rias:
- `DATABASE_URL`: String de conex√£o com PostgreSQL
- `API_PORT`: Porta da API (padr√£o: 8000)
- `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`: Credenciais do banco
- `STATS_CACHE_TTL`: TTL do cache de estat√≠sticas (segundos)
- `LOG_LEVEL`: N√≠vel de logging (DEBUG, INFO, WARNING, ERROR)

### `.dockerignore`
Exclui arquivos desnecess√°rios do build:
- `.venv/`, `__pycache__/`, `.git/`
- `data/raw/`, `data/reference/` (dados locais n√£o v√£o pro container)
- `.md` (exceto README.md)

### `Dockerfile`
Imagem otimizada para produ√ß√£o:
- Base: `python:3.11-slim`
- Health check configurado
- Depend√™ncias compiladas (psycopg)
- Multi-stage build (apenas runtime)

---

##  Licen√ßa

Este projeto foi desenvolvido para fins de avalia√ß√£o t√©cnica.

---

##  Autor

Desenvolvido como parte do processo seletivo para Engenheiro de Dados na **IntuitiveCare**.
