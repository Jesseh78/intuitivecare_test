# IntuitiveCare - Pipeline ETL e API de AnÃ¡lise de Despesas

##  VisÃ£o Geral

Este projeto implementa uma soluÃ§Ã£o completa de **ETL (Extract, Transform, Load)** para anÃ¡lise de despesas de operadoras de planos de saÃºde brasileiras, utilizando dados pÃºblicos da **ANS (AgÃªncia Nacional de SaÃºde Suplementar)**.

### O que o projeto faz:

1. **Pipeline ETL automatizado**:
   - Baixa automaticamente os Ãºltimos 3 trimestres de demonstraÃ§Ãµes contÃ¡beis da ANS
   - Valida e enriquece dados com cadastro de operadoras ativas
   - Agrega informaÃ§Ãµes por operadora e UF
   - Exporta dados processados para PostgreSQL

2. **Banco de dados PostgreSQL**:
   - Schema normalizado com constraints e Ã­ndices
   - Views materializadas para consultas otimizadas
   - Queries analÃ­ticas prÃ©-construÃ­das (top 5, crescimento, etc.)

3. **API REST (FastAPI)**:
   - Listagem de operadoras com paginaÃ§Ã£o e busca
   - HistÃ³rico de despesas por operadora
   - EstatÃ­sticas agregadas com cache em memÃ³ria
   - DocumentaÃ§Ã£o interativa (Swagger)

---

##  Requisitos

### ObrigatÃ³rios:
- **Python 3.10+**
- **Docker Desktop** (para PostgreSQL)
- **Git**

### Bibliotecas Python (instaladas via requirements.txt):
- `pandas` (processamento de dados)
- `requests` (download de arquivos ANS)
- `fastapi` + `uvicorn` (API REST)
- `psycopg[binary]` (PostgreSQL driver)
- `openpyxl` (leitura de Excel)

---

##  Setup RÃ¡pido

### ğŸš€ Setup Automatizado (Recomendado)

Para rodar **tudo** (Pipeline ETL + PostgreSQL + API + Testes) com um Ãºnico comando:

**Windows (PowerShell):**
```powershell
.\setup.ps1
```

**Linux/Mac:**
```bash
chmod +x setup.sh
./setup.sh
```

Este script automatizado irÃ¡:
- âœ… Criar virtual environment e instalar dependÃªncias
- âœ… Iniciar PostgreSQL no Docker (porta 5434)
- âœ… Executar pipeline ETL completo (Step 1â†’2â†’3)
- âœ… Carregar dados no PostgreSQL
- âœ… Rodar testes automatizados
- âœ… Iniciar API REST (porta 8000)

---

### âš™ï¸ Setup Manual

VocÃª pode executar o projeto de **duas formas**:
- **OpÃ§Ã£o A**: Com Docker (recomendado) - tudo containerizado
- **OpÃ§Ã£o B**: Desenvolvimento local - API local + DB Docker

---

### OpÃ§Ã£o A: Setup com Docker (Recomendado)

#### 1. Clone o repositÃ³rio
```bash
git clone <url-do-repo>
cd intuitivecare_test
```

#### 2. Configure as variÃ¡veis de ambiente
```bash
# Copie o template e edite se necessÃ¡rio
cp .env.example .env

# Ou no Windows
copy .env.example .env
```

#### 3. Inicie todos os serviÃ§os (API + DB)
```bash
docker-compose up -d
```

**O que isso faz:**
- âœ… Cria o banco PostgreSQL na porta **5434**
- âœ… Builda a imagem da API
- âœ… Inicia a API na porta **8000**
- âœ… Configura rede e health checks

#### 4. Verifique se os containers estÃ£o rodando
```bash
docker ps
```

VocÃª deve ver:
```
CONTAINER ID   IMAGE                    STATUS         PORTS
abc123         intuitivecare_test-api   Up 30 seconds  0.0.0.0:8000->8000/tcp
def456         postgres:16              Up 30 seconds  0.0.0.0:5434->5432/tcp
```

#### 5. Acesse a API
- **Swagger UI**: http://localhost:8000/docs
- **Health check**: http://localhost:8000/api/operadoras?limit=1

#### 6. Para parar os serviÃ§os
```bash
# Parar sem remover containers
docker-compose stop

# Parar e remover containers
docker-compose down

# Parar e remover TUDO (incluindo volumes/dados)
docker-compose down -v
```

---

### OpÃ§Ã£o B: Setup Local (Desenvolvimento)

#### 1. Clone o repositÃ³rio
```bash
git clone <url-do-repo>
cd intuitivecare_test
```

#### 2. Crie e ative o ambiente virtual
```bash
# Windows PowerShell
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Windows CMD
python -m venv .venv
.venv\Scripts\activate.bat

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

#### 3. Instale as dependÃªncias
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 4. Inicie apenas o banco de dados
```bash
docker-compose up -d db
```

#### 5. Configure a variÃ¡vel de ambiente para localhost
```bash
# Windows PowerShell
$env:DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"

# Windows CMD
set DATABASE_URL=postgresql://intuitive:intuitive@localhost:5434/intuitivecare

# Linux/Mac
export DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"
```

**Nota**: Use porta **5434** (externa) quando a API roda localmente!

---

## ğŸ˜ ConfiguraÃ§Ã£o do PostgreSQL

### Testar conexÃ£o com o banco
```bash
# Windows PowerShell
docker exec -it intuitivecare_pg psql -U intuitive -d intuitivecare -c "SELECT version();"
```

**ConfiguraÃ§Ãµes do banco**:
- **Host**: `localhost` (API local) ou `db` (API Docker)
- **Porta**: `5434` (API local) ou `5432` (API Docker)
- **UsuÃ¡rio**: `intuitive`
- **Senha**: `intuitive`
- **Database**: `intuitivecare`

---

##  Executar o Pipeline ETL

O pipeline Ã© dividido em 3 etapas sequenciais:

### Step 1: Baixar e consolidar dados da ANS
```bash
python -m src.cli step1
```

**O que faz**:
- Acessa o FTP pÃºblico da ANS
- Identifica os Ãºltimos 3 trimestres disponÃ­veis
- Baixa ZIPs das demonstraÃ§Ãµes contÃ¡beis
- Extrai e normaliza tabelas (CSV/Excel)
- Gera: `data/processed/consolidado_despesas.csv`

**Colunas geradas**: `CNPJ, RazaoSocial, Ano, Trimestre, ValorDespesas`

---

### Step 2: Validar, enriquecer e agregar
```bash
python -m src.cli step2 --invalid-cnpj-strategy keep_mark
```

**O que faz**:
- Valida CNPJs (dÃ­gitos verificadores)
- Baixa cadastro de operadoras ativas da ANS
- Enriquece com: `RegistroANS, Modalidade, UF`
- Gera agregaÃ§Ãµes por operadora/UF (total, mÃ©dia, desvio padrÃ£o)

**Arquivos gerados**:
- `data/processed/consolidado_enriquecido.csv`
- `data/processed/operadoras_ativas_normalizado.csv`
- `data/processed/despesas_agregadas.csv`
- `data/processed/invalid_rows_step2.csv` (CNPJs invÃ¡lidos, se `keep_mark`)
- `data/processed/join_sem_match_step2.csv` (CNPJs sem match no cadastro)

**OpÃ§Ãµes de estratÃ©gia**:
- `--invalid-cnpj-strategy drop`: Remove linhas com CNPJ invÃ¡lido
- `--invalid-cnpj-strategy keep_mark` (**recomendado**): MantÃ©m marcado para auditoria

---

### Step 3: Exportar para SQL
```bash
python -m src.cli export-sql
```

**O que faz**:
- Converte colunas para snake_case (padrÃ£o SQL)
- Gera CSVs prontos para `\copy` do PostgreSQL
- Salva em: `data/sql_data/`

**Arquivos gerados**:
- `operadoras_ativas.csv`
- `consolidado_enriquecido.csv`
- `despesas_agregadas.csv`
- `consolidado_despesas.csv` (cÃ³pia do step1)

---

##  Aplicar Schema e Views no PostgreSQL

### 1. Criar tabelas e Ã­ndices
```bash
# Windows PowerShell
type sql\01_schema.sql | docker exec -i intuitivecare_pg psql -U intuitive -d intuitivecare

# Linux/Mac
cat sql/01_schema.sql | docker exec -i intuitivecare_pg psql -U intuitive -d intuitivecare
```

**Tabelas criadas**:
- `operadoras_ativas` (PK: cnpj)
- `despesas_trimestrais` (FK â†’ operadoras_ativas)
- `despesas_agregadas` (estatÃ­sticas prÃ©-calculadas)

---

### 2. Criar views
```bash
# Windows PowerShell
type sql\04_views.sql | docker exec -i intuitivecare_pg psql -U intuitive -d intuitivecare
```

**Views criadas**:
- `operadoras_ativas_view` (une cadastro + razÃ£o social das despesas)

---

##  Carga de Dados no PostgreSQL

### 1. Copie os CSVs para dentro do container
```bash
docker cp data/sql_data/. intuitivecare_pg:/tmp/sql_data/
```

### 2. Execute a carga via psql
```bash
# Windows PowerShell
docker exec -it intuitivecare_pg psql -U intuitive -d intuitivecare
```

Dentro do psql:
```sql
-- Limpa dados anteriores (se re-executar)
TRUNCATE TABLE despesas_trimestrais CASCADE;
TRUNCATE TABLE despesas_agregadas RESTART IDENTITY;
TRUNCATE TABLE operadoras_ativas CASCADE;

-- Carga: operadoras ativas
\copy operadoras_ativas (cnpj, registro_ans, modalidade, uf) FROM '/tmp/sql_data/operadoras_ativas.csv' WITH (FORMAT csv, HEADER true, ENCODING 'UTF8');

-- Carga: despesas trimestrais enriquecidas
\copy despesas_trimestrais (cnpj, razao_social, trimestre, ano, valor_despesas, registro_ans, modalidade, uf) FROM '/tmp/sql_data/consolidado_enriquecido.csv' WITH (FORMAT csv, HEADER true, ENCODING 'UTF8');

-- Carga: agregados
\copy despesas_agregadas (razao_social, uf, total_despesas, media_despesas_tri, desvio_padrao_despesas) FROM '/tmp/sql_data/despesas_agregadas.csv' WITH (FORMAT csv, HEADER true, ENCODING 'UTF8');

-- Verifica
SELECT COUNT(*) FROM operadoras_ativas;
SELECT COUNT(*) FROM despesas_trimestrais;
SELECT COUNT(*) FROM despesas_agregadas;

\q
```

**Importante**: Use `CASCADE` no TRUNCATE para respeitar a FK entre tabelas.

---

##  Rodar a API REST

### OpÃ§Ã£o A: API via Docker (jÃ¡ estÃ¡ rodando!)

Se vocÃª usou `docker-compose up -d`, a API jÃ¡ estÃ¡ disponÃ­vel em:
- **Base URL**: http://localhost:8000
- **Swagger**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

**Logs da API**:
```bash
# Ver logs em tempo real
docker logs -f intuitivecare_api

# Ver Ãºltimas 100 linhas
docker logs --tail 100 intuitivecare_api
```

**Rebuild da imagem** (apÃ³s mudanÃ§as no cÃ³digo):
```bash
docker-compose up -d --build api
```

---

### OpÃ§Ã£o B: API local (desenvolvimento)

#### 1. Configure a variÃ¡vel de ambiente
```bash
# Windows PowerShell
$env:DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"

# Windows CMD
set DATABASE_URL=postgresql://intuitive:intuitive@localhost:5434/intuitivecare

# Linux/Mac
export DATABASE_URL="postgresql://intuitive:intuitive@localhost:5434/intuitivecare"
```

**Ou crie arquivo `.env`**:
```bash
cp .env.example .env
```

Edite `.env` e ajuste `DATABASE_URL`:
```
DATABASE_URL=postgresql://intuitive:intuitive@localhost:5434/intuitivecare
```

#### 2. Inicie o servidor
```bash
uvicorn src.api.main:app --reload --port 8000
```

#### 3. Acesse a documentaÃ§Ã£o interativa
- Swagger UI: **http://localhost:8000/docs**
- ReDoc: **http://localhost:8000/redoc**

---

##  Endpoints da API

### 1. **GET** `/api/operadoras` - Listar operadoras
**PaginaÃ§Ã£o + filtro por razÃ£o social ou CNPJ**

```bash
# Listar primeira pÃ¡gina (10 itens)
curl "http://localhost:8000/api/operadoras?page=1&limit=10"

# Buscar por razÃ£o social
curl "http://localhost:8000/api/operadoras?q=UNIMED"

# Buscar por CNPJ
curl "http://localhost:8000/api/operadoras?q=12345678"
```

**Resposta**:
```json
{
  "data": [
    {
      "cnpj": "12345678000199",
      "razao_social": "UNIMED EXAMPLE COOPERATIVA",
      "registro_ans": "123456",
      "modalidade": "Cooperativa MÃ©dica",
      "uf": "SP"
    }
  ],
  "total": 150,
  "page": 1,
  "limit": 10
}
```

---

### 2. **GET** `/api/operadoras/{cnpj}` - Detalhes de uma operadora
```bash
curl "http://localhost:8000/api/operadoras/12345678000199"
```

**Resposta**:
```json
{
  "cnpj": "12345678000199",
  "razao_social": "UNIMED EXAMPLE COOPERATIVA",
  "registro_ans": "123456",
  "modalidade": "Cooperativa MÃ©dica",
  "uf": "SP"
}
```

---

### 3. **GET** `/api/operadoras/{cnpj}/despesas` - HistÃ³rico de despesas
```bash
curl "http://localhost:8000/api/operadoras/12345678000199/despesas"
```

**Resposta**:
```json
[
  {
    "ano": 2025,
    "trimestre": 1,
    "valor_despesas": 1500000.00
  },
  {
    "ano": 2025,
    "trimestre": 2,
    "valor_despesas": 1750000.00
  }
]
```

---

### 4. **GET** `/api/estatisticas` - EstatÃ­sticas agregadas
**Cache em memÃ³ria (TTL: 5 minutos)**

```bash
# Normal (usa cache se disponÃ­vel)
curl "http://localhost:8000/api/estatisticas"

# ForÃ§ar recÃ¡lculo (ignora cache)
curl "http://localhost:8000/api/estatisticas?force=true"
```

**Resposta**:
```json
{
  "total_despesas": 15000000000.00,
  "media_despesas": 2500000.00,
  "top5_operadoras": [
    {
      "razao_social": "BRADESCO SAUDE S/A",
      "total_despesas": 500000000.00
    }
  ],
  "distribuicao_por_uf": [
    {
      "uf": "SP",
      "total_despesas": 8000000000.00
    }
  ],
  "cached": true
}
```

---

## ğŸ§ª Testes

O projeto inclui **testes unitÃ¡rios e de integraÃ§Ã£o** usando pytest.

### Executar todos os testes

```bash
# Instale dependÃªncias de desenvolvimento
pip install -r requirements-dev.txt

# Execute todos os testes
pytest

# Com coverage report
pytest --cov=src --cov-report=html

# Apenas testes unitÃ¡rios
pytest tests/test_cnpj.py tests/test_parse_valor.py tests/test_aggregate.py

# Apenas testes de integraÃ§Ã£o (API)
pytest tests/test_api.py
```

### Cobertura de testes

Os testes cobrem:

**UnitÃ¡rios** (11 testes):
- âœ… ValidaÃ§Ã£o de CNPJ (vÃ¡lidos, invÃ¡lidos, formatados)
- âœ… NormalizaÃ§Ã£o de CNPJ (remoÃ§Ã£o de pontos, barras, etc.)
- âœ… Parse de valores monetÃ¡rios (formato BR e internacional)
- âœ… AgregaÃ§Ãµes (total, mÃ©dia, desvio padrÃ£o)

**IntegraÃ§Ã£o** (9 testes):
- âœ… GET `/api/operadoras` - retorna 200 com paginaÃ§Ã£o
- âœ… GET `/api/operadoras?q=` - filtro de busca
- âœ… GET `/api/operadoras/{cnpj}` - detalhes operadora
- âœ… GET `/api/operadoras/{cnpj}` - retorna 404 se nÃ£o existir
- âœ… GET `/api/operadoras/{cnpj}/despesas` - histÃ³rico
- âœ… GET `/api/estatisticas` - campos obrigatÃ³rios
- âœ… GET `/api/estatisticas?force=true` - forÃ§a refresh
- âœ… GET `/docs` - Swagger disponÃ­vel
- âœ… GET `/redoc` - ReDoc disponÃ­vel

### Estrutura de testes

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_cnpj.py          # ValidaÃ§Ã£o e normalizaÃ§Ã£o de CNPJ (11 testes)
â”œâ”€â”€ test_parse_valor.py   # Parse de valores monetÃ¡rios (10 testes)
â”œâ”€â”€ test_aggregate.py     # AgregaÃ§Ãµes estatÃ­sticas (8 testes)
â””â”€â”€ test_api.py           # Testes de integraÃ§Ã£o da API (9 testes)
```

### Visualizar relatÃ³rio de coverage

ApÃ³s executar `pytest --cov`, abra:
```
htmlcov/index.html
```

---

##  Logging e Monitoramento

A API possui logging estruturado para facilitar debug e monitoramento.

### NÃ­veis de log

- **INFO**: Startup, conexÃ£o DB, requisiÃ§Ãµes principais
- **DEBUG**: Detalhes de queries, cache hits
- **WARNING**: HTTPException (404, 400, etc.)
- **ERROR**: ExceÃ§Ãµes nÃ£o tratadas, erros de banco

### Exemplos de logs

**Startup da API:**
```
2026-02-03 10:30:00 - src.api.main - INFO - ğŸš€ Iniciando API IntuitiveCare...
2026-02-03 10:30:01 - src.api.db - INFO - ConfiguraÃ§Ã£o de banco de dados carregada
2026-02-03 10:30:01 - src.api.main - INFO - âœ… Conectado ao PostgreSQL: PostgreSQL 16.1...
2026-02-03 10:30:01 - src.api.main - INFO - âœ… API pronta para receber requisiÃ§Ãµes
```

**RequisiÃ§Ãµes:**
```
2026-02-03 10:31:15 - src.api.main - INFO - GET /api/operadoras - page=1, limit=10, q=None
2026-02-03 10:31:15 - src.api.service - DEBUG - Listagem: 10 operadoras retornadas (total: 150)
```

**EstatÃ­sticas (cache):**
```
2026-02-03 10:32:00 - src.api.main - INFO - GET /api/estatisticas - force_refresh=False
2026-02-03 10:32:00 - src.api.main - INFO - EstatÃ­sticas retornadas do cache
```

**Erros:**
```
2026-02-03 10:33:00 - src.api.main - WARNING - HTTPException 404: Operadora com CNPJ 99999999999999 nÃ£o encontrada - http://localhost:8000/api/operadoras/99999999999999
```

### Configurar nÃ­vel de log

**Via variÃ¡vel de ambiente** (`.env`):
```bash
LOG_LEVEL=DEBUG  # Para desenvolvimento
LOG_LEVEL=INFO   # Para produÃ§Ã£o (padrÃ£o)
```

**Logs do container Docker:**
```bash
# Ver logs em tempo real
docker logs -f intuitivecare_api

# Filtrar por nÃ­vel
docker logs intuitivecare_api 2>&1 | grep ERROR

# Ãšltimas 100 linhas
docker logs --tail 100 intuitivecare_api
```

### Health check endpoint

A API possui um endpoint `/health` para monitoramento:
```bash
curl http://localhost:8000/health
```

**Resposta (healthy):**
```json
{
  "status": "healthy",
  "database": "connected"
}
```

**Resposta (unhealthy - 503):**
```json
{
  "status": "unhealthy",
  "database": "disconnected",
  "error": "connection refused"
}
```

---

##  Estrutura do Projeto

```
intuitivecare_test/
â”‚
â”œâ”€â”€ data/                                    # Dados processados
â”‚   â”œâ”€â”€ raw/                                 # CSVs baixados da ANS (por trimestre)
â”‚   â”œâ”€â”€ processed/                           # SaÃ­da do pipeline (consolidado, enriquecido, etc.)
â”‚   â”œâ”€â”€ reference/                           # Cadastros baixados da ANS
â”‚   â””â”€â”€ sql_data/                            # CSVs prontos para carga no PostgreSQL
â”‚
â”œâ”€â”€ sql/                                     # Scripts SQL
â”‚   â”œâ”€â”€ 01_schema.sql                        # CREATE TABLE + Ã­ndices
â”‚   â”œâ”€â”€ 02_load.sql                          # Exemplo de \copy (referÃªncia)
â”‚   â”œâ”€â”€ 03_queries.sql                       # Queries analÃ­ticas (top 5, crescimento, UFs)
â”‚   â””â”€â”€ 04_views.sql                         # CREATE VIEW (operadoras_ativas_view)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                                 # API REST (FastAPI)
â”‚   â”‚   â”œâ”€â”€ main.py                          # Rotas e endpoints
â”‚   â”‚   â”œâ”€â”€ schemas.py                       # Pydantic models (request/response)
â”‚   â”‚   â”œâ”€â”€ service.py                       # LÃ³gica de negÃ³cio (queries SQL)
â”‚   â”‚   â””â”€â”€ db.py                            # ConexÃ£o com PostgreSQL (psycopg)
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                            # Pipeline ETL
â”‚   â”‚   â”œâ”€â”€ ans_fetch.py                     # Step 1: baixa e consolida dados ANS
â”‚   â”‚   â”œâ”€â”€ validate_enrich.py               # Step 2: valida CNPJ, enriquece com cadastro
â”‚   â”‚   â”œâ”€â”€ aggregate.py                     # Step 2: agrega por operadora/UF
â”‚   â”‚   â””â”€â”€ export_sql_data.py               # Step 3: prepara CSVs para PostgreSQL
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                               # UtilitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ fs.py                            # Helpers para sistema de arquivos
â”‚   â”‚   â””â”€â”€ http.py                          # Download de arquivos (requests)
â”‚   â”‚
â”‚   â””â”€â”€ cli.py                               # Interface de linha de comando (argparse)
â”‚
â”œâ”€â”€ tests/                                   # Testes automatizados (pytest)
â”‚   â”œâ”€â”€ test_cnpj.py                         # ValidaÃ§Ã£o e normalizaÃ§Ã£o de CNPJ
â”‚   â”œâ”€â”€ test_parse_valor.py                 # Parse de valores monetÃ¡rios
â”‚   â”œâ”€â”€ test_aggregate.py                   # AgregaÃ§Ãµes estatÃ­sticas
â”‚   â””â”€â”€ test_api.py                         # Testes de integraÃ§Ã£o da API
â”‚
â”œâ”€â”€ .dockerignore                            # Arquivos excluÃ­dos do build Docker
â”œâ”€â”€ .env.example                             # Template de variÃ¡veis de ambiente
â”œâ”€â”€ docker-compose.yml                       # OrquestraÃ§Ã£o (API + PostgreSQL)
â”œâ”€â”€ Dockerfile                               # Imagem Docker da API
â”œâ”€â”€ pytest.ini                               # ConfiguraÃ§Ã£o do pytest
â”œâ”€â”€ requirements.txt                         # DependÃªncias de produÃ§Ã£o
â”œâ”€â”€ requirements-dev.txt                     # DependÃªncias de desenvolvimento
â””â”€â”€ README.md                                # Este arquivo
```

---

##  DecisÃµes TÃ©cnicas e Tradeoffs

### 1. **EstratÃ©gia `keep_mark` para CNPJs invÃ¡lidos**
**Por quÃª?**  
- MantÃ©m rastreabilidade para auditoria
- Permite identificar problemas nos dados da ANS
- NÃ£o perde informaÃ§Ã£o (pode ser corrigida manualmente)

**Tradeoff**:  
- âŒ Gera linhas Ã³rfÃ£s (sem FK vÃ¡lida)
- âœ… MantÃ©m integridade analÃ­tica (saber o que foi descartado)

**Alternativa**: `drop` (remove silenciosamente, pode esconder problemas)

---

### 2. **Encoding `latin-1` para cadastro ANS**
**Por quÃª?**  
- Arquivos da ANS usam `Windows-1252` (nÃ£o UTF-8)
- Evita `UnicodeDecodeError` ao ler CSVs com acentuaÃ§Ã£o

**Tradeoff**:  
- âŒ NÃ£o Ã© portÃ¡vel (depende do encoding do servidor ANS)
- âœ… Funciona com dados reais (testado)

**Alternativa**: Converter manualmente para UTF-8 (adiciona etapa extra)

---

### 3. **Cache em memÃ³ria (5 minutos) para estatÃ­sticas**
**Por quÃª?**  
- Reduz carga no banco para queries pesadas (SUM, AVG, GROUP BY)
- API responde mais rÃ¡pido (< 10ms vs 500ms)

**Tradeoff**:  
- âŒ Dados podem estar desatualizados por atÃ© 5 minutos
- âœ… Escalabilidade (suporta mais requests simultÃ¢neos)

**Alternativa**: Cache em Redis (mais complexo, mas distribuÃ­do)

---

### 4. **Porta 5434 (nÃ£o 5432) para PostgreSQL**
**Por quÃª?**  
- Evita conflito com PostgreSQL local (porta padrÃ£o 5432)
- Facilita desenvolvimento (mÃºltiplos projetos)

**Tradeoff**:  
- âŒ Precisa lembrar de configurar porta customizada
- âœ… Isolamento total (nÃ£o interfere com outros bancos)

---

### 5. **Download automÃ¡tico vs. manual da ANS**
**Por quÃª?**  
- Automatiza coleta (reduz erro humano)
- Identifica Ãºltimo trimestre disponÃ­vel dinamicamente

**Tradeoff**:  
- âŒ Depende de disponibilidade do FTP ANS (pode cair)
- âœ… AtualizaÃ§Ã£o automÃ¡tica (executar step1 novamente sempre busca Ãºltimos dados)

**Alternativa**: Fornecer CSVs manualmente (mais controle, menos automaÃ§Ã£o)

---

### 6. **FK com DEFERRABLE INITIALLY DEFERRED**
**Por quÃª?**  
- Permite carga em qualquer ordem (operadoras â†’ despesas ou vice-versa)
- Evita erro de violaÃ§Ã£o de FK durante `\copy`

**Tradeoff**:  
- âŒ ValidaÃ§Ã£o acontece sÃ³ no COMMIT (erros aparecem mais tarde)
- âœ… Flexibilidade na carga (nÃ£o precisa respeitar ordem estrita)

---

### 7. **Pandas para ETL (nÃ£o Spark/Dask)**
**Por quÃª?**  
- Volume de dados pequeno (~50-100MB por trimestre)
- Simplicidade (sem cluster, menos dependÃªncias)

**Tradeoff**:  
- âŒ NÃ£o escala para Big Data (limite: ~1-2GB de RAM)
- âœ… Setup rÃ¡pido, fÃ¡cil debug

**Alternativa**: Spark/Dask (overkill para esse volume)

---

### 8. **FastAPI (nÃ£o Flask/Django)**
**Por quÃª?**  
- Performance (assÃ­ncrono por padrÃ£o)
- ValidaÃ§Ã£o automÃ¡tica (Pydantic)
- DocumentaÃ§Ã£o Swagger embutida

**Tradeoff**:  
- âŒ Menos maturidade que Flask (menos plugins)
- âœ… CÃ³digo mais limpo (type hints nativos)

---

## ğŸ”§ Troubleshooting

### Problema 1: **Container da API nÃ£o inicia**
```
Error: Cannot connect to database
```

**SoluÃ§Ã£o**: Certifique-se que o DB estÃ¡ rodando e healthy:
```bash
docker ps

# Se o DB nÃ£o estiver UP, reinicie
docker-compose restart db

# Aguarde o health check
docker logs intuitivecare_pg | grep "ready to accept connections"

# Reinicie a API
docker-compose restart api
```

---

### Problema 2: **Porta 8000 jÃ¡ estÃ¡ em uso**
```
Error: address already in use
```

**SoluÃ§Ã£o**: Mude a porta no `.env`:
```
API_PORT=8001
```

Ou pare o processo que estÃ¡ usando:
```bash
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

---

### Problema 3: **SSL Error ao baixar da ANS**
```
SSLError: [SSL: CERTIFICATE_VERIFY_FAILED]
```

**SoluÃ§Ã£o**:
```python
# Adicione verify=False no requests (src/utils/http.py)
# Apenas para desenvolvimento local!
response = requests.get(url, verify=False)
```

---

### Problema 4: **Encoding error ao ler cadastro**
```
UnicodeDecodeError: 'utf-8' codec can't decode byte
```

**SoluÃ§Ã£o**: Cadastro ANS usa `latin-1`, jÃ¡ configurado em `validate_enrich.py`:
```python
cad = pd.read_csv(path, encoding="latin-1", sep=";")
```

---

### Problema 3: **FK constraint error na carga**
```
ERROR: insert or update on table "despesas_trimestrais" violates foreign key
```

**SoluÃ§Ã£o**: Limpe na ordem correta:
```sql
TRUNCATE TABLE despesas_trimestrais CASCADE;
TRUNCATE TABLE operadoras_ativas CASCADE;
```

Ou use `DEFERRABLE` (jÃ¡ configurado no schema).

---

### Problema 7: **Windows nÃ£o reconhece variÃ¡vel de ambiente**
```bash
# PowerShell
$env:DATABASE_URL="postgresql://..."

# CMD
set DATABASE_URL=postgresql://...
```

**Alternativa**: Crie arquivo `.env`:
```bash
cp .env.example .env
```

E a API lerÃ¡ automaticamente (com `python-dotenv`).

---

### Problema 8: **Container PostgreSQL nÃ£o inicia**
```
Error: port 5434 already in use
```

**SoluÃ§Ã£o**:
```bash
# Verifique processo usando a porta
netstat -ano | findstr :5434

# Ou mude a porta no docker-compose.yml
ports:
  - "5435:5432"  # Porta externa diferente
```

---

### Problema 6: **Dados nÃ£o aparecem na API**
**Checklist**:
1. Pipeline executado? (`step1` â†’ `step2` â†’ `export-sql`)
2. Schema criado? (`01_schema.sql`)
3. Carga feita? (`\copy` dos CSVs)
4. Views criadas? (`04_views.sql`)
5. `DATABASE_URL` correto?

**Debug**:
```bash
docker exec -it intuitivecare_pg psql -U intuitive -d intuitivecare -c "SELECT COUNT(*) FROM despesas_trimestrais;"
```

---

##  ReferÃªncias

- **Dados pÃºblicos ANS**: https://dadosabertos.ans.gov.br/
- **FastAPI Docs**: https://fastapi.tiangolo.com/
- **PostgreSQL COPY**: https://www.postgresql.org/docs/current/sql-copy.html
- **Pandas Docs**: https://pandas.pydata.org/docs/
- **Docker Docs**: https://docs.docker.com/

---

##  Arquivos de ConfiguraÃ§Ã£o

### `.env.example`
Template com todas as variÃ¡veis de ambiente necessÃ¡rias:
- `DATABASE_URL`: String de conexÃ£o com PostgreSQL
- `API_PORT`: Porta da API (padrÃ£o: 8000)
- `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`: Credenciais do banco
- `STATS_CACHE_TTL`: TTL do cache de estatÃ­sticas (segundos)
- `LOG_LEVEL`: NÃ­vel de logging (DEBUG, INFO, WARNING, ERROR)

### `.dockerignore`
Exclui arquivos desnecessÃ¡rios do build:
- `.venv/`, `__pycache__/`, `.git/`
- `data/raw/`, `data/reference/` (dados locais nÃ£o vÃ£o pro container)
- `.md` (exceto README.md)

### `Dockerfile`
Imagem otimizada para produÃ§Ã£o:
- Base: `python:3.11-slim`
- Health check configurado
- DependÃªncias compiladas (psycopg)
- Multi-stage build (apenas runtime)

---

##  LicenÃ§a

Este projeto foi desenvolvido para fins de avaliaÃ§Ã£o tÃ©cnica.

---

##  Autor JosÃ© Ulisses

Desenvolvido como parte do processo seletivo para Estagiario na **IntuitiveCare**.
